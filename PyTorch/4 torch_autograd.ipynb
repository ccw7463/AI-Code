{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 간단한 신경망 연산 표현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "출력 < -- 비교 -- > 예측값 = 입력 * 가중치 + 편향"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6995, 0.5062, 0.8033, 0.8676, 0.1050])\n",
      "tensor([[-0.7440, -0.8713,  0.3723],\n",
      "        [-0.1205, -0.1574,  0.7469],\n",
      "        [ 0.1624, -0.8205, -0.7742],\n",
      "        [ 2.0875, -0.0405, -2.1411],\n",
      "        [ 0.8769, -0.7643,  0.2188]], requires_grad=True)\n",
      "tensor([-1.9278,  0.4208,  0.2872], requires_grad=True)\n",
      "tensor([-0.4755, -1.0429, -1.5309], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 예측값 y_hat = 입력(x) * 가중치(w) + 편향(b)\n",
    "x = torch.rand(5)\n",
    "w = torch.randn(5,3,requires_grad=True) # 미분가능설정 / 데이터정의시 또는 x.requires_grad_(True) 로 지정가능\n",
    "b = torch.randn(3,requires_grad=True) # 미분가능설정 / 데이터정의시 또는 x.requires_grad_(True) 로 지정가능\n",
    "y_hat = torch.matmul(x,w)+b\n",
    "print(x)\n",
    "print(w)\n",
    "print(b)\n",
    "print(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실제값\n",
    "y = torch.zeros(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3270, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Loss = 실제값과 예측값을 비교하여 손실값 구함\n",
    "loss = f.binary_cross_entropy_with_logits(y_hat,y)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<AddBackward0 object at 0x000001D9949A7388>\n",
      "<BinaryCrossEntropyWithLogitsBackward0 object at 0x000001D9949A7948>\n"
     ]
    }
   ],
   "source": [
    "# grad_fn : 해당 텐서의 backpropagation에 대한 설명 확인 가능\n",
    "print(y_hat.grad_fn)\n",
    "print(loss.grad_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 역전파"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0894, 0.0608, 0.0415],\n",
      "        [0.0647, 0.0440, 0.0300],\n",
      "        [0.1026, 0.0698, 0.0476],\n",
      "        [0.1109, 0.0754, 0.0514],\n",
      "        [0.0134, 0.0091, 0.0062]])\n",
      "tensor([0.1278, 0.0869, 0.0593])\n"
     ]
    }
   ],
   "source": [
    "# 역전파 수행\n",
    "'''\n",
    "1. dloss/dw \n",
    "2. dloss/db \n",
    "'''\n",
    "loss.backward() \n",
    "\n",
    "# grad 값 확인\n",
    "print(w.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 미분 가능 여부"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# 1. 데이터 생성시 미분 가능 부여\n",
    "data = torch.randn(5,3,requires_grad=True)\n",
    "print(data.requires_grad)\n",
    "\n",
    "# 2. 데이터 생성후 미분 가능 부여\n",
    "data = torch.randn(5,3)\n",
    "data.requires_grad_(True)\n",
    "print(data.requires_grad)\n",
    "\n",
    "# 3. 미분 불가 (학습말고 테스트에서 사용)\n",
    "with torch.no_grad():\n",
    "    y_hat = torch.matmul(x, w)+b\n",
    "print(y_hat.requires_grad)\n",
    "\n",
    "# 4. 미분 불가 (학습말고 테스트에서 사용)\n",
    "y_hat = torch.matmul(x, w)+b\n",
    "y_hat = y_hat.detach()\n",
    "print(y_hat.requires_grad)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.15 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "98fb658fc8779e6136f671765f304aa90b381a69e0e3fde0fbe10c53a5640cfd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
